{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Machine_learning_project.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"lJB1l2hW9KEh","colab_type":"text"},"source":["# **Machine Learning**\n","### TensorFlow for Finance\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cuYxnzrgYDGW","colab_type":"text"},"source":["### Instituto Superior de Engenharia de Lisboa (ISEL)\n","### Licenciatura em Engenharia Informática e Multimédia (LEIM)\n","2019-2020\n","\n","Bavo Knaeps & Jitse Wierdsma"]},{"cell_type":"markdown","metadata":{"id":"IquqsFeP9KEj","colab_type":"text"},"source":["The models used for predicting the stock market are mostly Neural Networks. This is because stock prices don't follow a traditional 'line' that can be defined by functions. This means that a typical regression model will fail to predict the values accurately. We will show this in a small example."]},{"cell_type":"markdown","metadata":{"id":"YOAMbbIf9KEl","colab_type":"text"},"source":["First we install/import the packages we are going to use in this small case study."]},{"cell_type":"code","metadata":{"id":"OFAFs8zZ9KEm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":586},"outputId":"83fe4b41-9e27-494a-b2f1-7e160acf6370","executionInfo":{"status":"ok","timestamp":1575154071001,"user_tz":-60,"elapsed":12060,"user":{"displayName":"Jitse Wierdsma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA8hIhGegjl_BTyv004_anbBlaWTl6Bd7oIoW3Xjw=s64","userId":"13573355581921025641"}}},"source":["!pip install tensorflow\n","!pip install keras\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn import preprocessing\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.6.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (0.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.1.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"eYBlTQfH9KEq","colab_type":"text"},"source":["### Importing file\n","\n","First, we will import a .csv file. In this case we chose for a crypto coin called Bitcoin, because of the hype around cryptocurrency. There are also a lot of API's that support cryptocurrency that we can use, which will come in handy later on in the project.\n","\n","### Setting the target value\n","\n","In this case we want to predict the next open price of Bitcoin. We set the target of each row by creating a new column 'target_open' and shifting the value of the next row to this column. This means that now we have the next open price on each row.\n","\n","### Dropping rows and colums\n","\n","In this small case study we drop a few rows to improve the data for training the models. Some values never change so they will not influence the training and prediction process, they will only slow it down. \n","We drop the first row because it contains false data that might have a bad influence on the models. Next, we drop the last row. By creating the new column and shifting we create a NaN value in this cell for the last row. Model training has a hard time dealing with NaN value's. We could also solve this with the .getdummies() function but it's better to clean the data before using it.\n","\n","We set 2 columns, date and symbol, to be dropped. They do not influence the target_open in any way so they are rendered useless.\n","\n","### Setting the X and y values\n","\n","A model uses target and feature values for training and predicting values.\n","\n","By binding y to y = df[TARGET], we obtain only the target_open values of the dataframe.\n","\n","For our target values we bind X to df[FEATURES] where FEATURES = df.columns. We previously dropped all the columns that are useless so we can use this function safely."]},{"cell_type":"code","metadata":{"id":"qZSMj7YQ9KEr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":314},"outputId":"25435bde-ff39-4247-ffe2-6f82fc1dd8c8","executionInfo":{"status":"ok","timestamp":1575154159516,"user_tz":-60,"elapsed":32320,"user":{"displayName":"Jitse Wierdsma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA8hIhGegjl_BTyv004_anbBlaWTl6Bd7oIoW3Xjw=s64","userId":"13573355581921025641"}}},"source":["df = pd.read_csv(\"./data.csv\")\n","df.head() # print the first lines of the file\n","\n","df[\"target_open\"] = df[\"High\"].shift(-1)\n","\n","#drop first (useless)\n","df.drop(0, inplace = True)\n","#drop last row (contains NaN)\n","df.drop(len(df),inplace=True)\n","\n","drop = [\"Date\",\"Symbol\"]\n","#drop the date (useless for training) \n","#drop the symbol name (doesn't change so no use for training)\n","df.drop(df[drop], inplace = True, axis = 1)\n","\n","TARGET = [\"target_open\"]\n","FEATURES =  df.columns\n","\n","X = df[FEATURES]\n","X.drop(df[TARGET], inplace = True, axis = 1)\n","\n","y = df[TARGET]"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume BTC</th>\n","      <th>Volume USD</th>\n","      <th>target_open</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>7169.65</td>\n","      <td>7197.99</td>\n","      <td>7128.55</td>\n","      <td>7144.12</td>\n","      <td>346.46</td>\n","      <td>2482945.79</td>\n","      <td>7189.88</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7150.00</td>\n","      <td>7189.88</td>\n","      <td>7129.65</td>\n","      <td>7169.65</td>\n","      <td>380.62</td>\n","      <td>2725437.77</td>\n","      <td>7170.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7127.01</td>\n","      <td>7170.00</td>\n","      <td>7083.51</td>\n","      <td>7150.00</td>\n","      <td>708.60</td>\n","      <td>5046541.62</td>\n","      <td>7210.00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7210.00</td>\n","      <td>7210.00</td>\n","      <td>7110.30</td>\n","      <td>7127.01</td>\n","      <td>743.72</td>\n","      <td>5319075.80</td>\n","      <td>7232.44</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>7210.18</td>\n","      <td>7232.44</td>\n","      <td>7186.90</td>\n","      <td>7210.00</td>\n","      <td>306.71</td>\n","      <td>2211323.40</td>\n","      <td>7252.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Open     High      Low    Close  Volume BTC  Volume USD  target_open\n","1  7169.65  7197.99  7128.55  7144.12      346.46  2482945.79      7189.88\n","2  7150.00  7189.88  7129.65  7169.65      380.62  2725437.77      7170.00\n","3  7127.01  7170.00  7083.51  7150.00      708.60  5046541.62      7210.00\n","4  7210.00  7210.00  7110.30  7127.01      743.72  5319075.80      7232.44\n","5  7210.18  7232.44  7186.90  7210.00      306.71  2211323.40      7252.00"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"IURRgX2p9KEu","colab_type":"text"},"source":["### Normalization\n","\n","Some values influence the training process more than others (by being such large numbers). That's why we need to normalize the data so that each column has an equally relevant impact on the models."]},{"cell_type":"markdown","metadata":{"id":"9fQwY_oW9KEy","colab_type":"text"},"source":["### Splitting into train and test data \n","\n","To test a model, you require data that the *model* hasn't \"seen\" yet, but data that *you* know is correct. This so that you can analyze the accuracy of the model. We use the function train_test_split from sklearn to split these dataframes into train_X, test_X, train_y and test_y."]},{"cell_type":"code","metadata":{"id":"V8bu3hOH9KEz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"outputId":"78f70258-3afe-43bd-b041-e1a1d156c534","executionInfo":{"status":"ok","timestamp":1575154209294,"user_tz":-60,"elapsed":1027,"user":{"displayName":"Jitse Wierdsma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA8hIhGegjl_BTyv004_anbBlaWTl6Bd7oIoW3Xjw=s64","userId":"13573355581921025641"}}},"source":["train_X, test_X, train_y, test_y = train_test_split(X, y, \n","                                                    train_size=0.8,\n","                                                    test_size=0.2,\n","                                                    random_state=122)\n","# Visualizing the prices\n","plt.plot(df[TARGET])\n","plt.show()\n","# The data is sorted by date\n","# so the plot shows the fluctuations of the price over time."],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngP8HyasPFjRuODIAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"UUgcFdRU9KE3","colab_type":"text"},"source":["### Sequential model\n","\n","The first model we are going to implement is the Sequential model.\n","\n","Sequential is a Module which contains other Modules, and applies them in sequence to produce its output. Each Linear Module computes output from input using a linear function, and holds internal Tensors for its weight and bias.\n","\n","In this case we use dense layer modules*. On the input layer we set the shape of (6,), this is the shape of each row of the X values. Next we define 2 more layers. The second contains 50 nodes and the third contains 20. \n","Finally, we set the final layer to 1 node as output.\n","\n","*Dense implements the operation: `output = activation(dot(input, kernel) + bias)`, where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True).\n","\n","### Optimizing \n","\n","The optimizer we are using is called Adam. Adam is an adaptive learning rate optimization algorithm that’s been designed specifically for training deep neural networks. To show the progress of the model we use MSE and accuracy while training.\n","\n","### Fitting the data\n","\n","To train the model we have to fit the model. We also set the epoch hyperparameter (this is so it doesn't take too long). While fitting you can follow the progress in the output. \n","\n","### Score and predict\n","\n","Now we want to know how good our model is so we are going to predict a value and see if it's close to the actual value. The will be different after each training session. To check the score of the model we use the method 'evaluate' with the params test_X and test_y. This method will then predict each row and check how accurate it is compared to the actual value. After that, the method will return how accurate it actually is. In this case it's not that accurate because we need to test with more layers, diffrent modules, ... "]},{"cell_type":"code","metadata":{"id":"478n6oAf9KE5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b8a22e23-14f8-4939-f326-942980ded27d","executionInfo":{"status":"ok","timestamp":1575155787121,"user_tz":-60,"elapsed":98417,"user":{"displayName":"Jitse Wierdsma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA8hIhGegjl_BTyv004_anbBlaWTl6Bd7oIoW3Xjw=s64","userId":"13573355581921025641"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from sklearn import preprocessing\n","from keras import losses\n","from keras.optimizers import SGD\n","\n","# normalize to ease training\n","min_max_scaler = preprocessing.MinMaxScaler()\n","y_scaled = min_max_scaler.fit_transform(train_y.values)\n","x_scaled = min_max_scaler.fit_transform(train_X.values)\n","train_y= pd.DataFrame(y_scaled)\n","train_X = pd.DataFrame(x_scaled)\n","\n","model = keras.Sequential([\n","    keras.layers.Dense(10, activation=tf.nn.relu, input_shape = (6,)),\n","    keras.layers.Dense(50, activation=tf.nn.relu),\n","    keras.layers.Dense(20, activation=tf.nn.softmax),\n","    keras.layers.Dense(1),\n","])\n","\n","model.compile(optimizer=\"adam\", \n","              loss=losses.mean_squared_error,\n","              metrics=['accuracy'])\n","\n","model.fit(train_X, train_y, epochs=100)\n","\n","test_X =  pd.DataFrame(min_max_scaler.fit_transform(test_X.values))\n","test_y = pd.DataFrame(min_max_scaler.fit_transform(test_y.values))\n","\n","pred = pd.DataFrame(min_max_scaler.inverse_transform(model.predict(test_X)))\n","print (model.evaluate(test_X,test_y))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Train on 16850 samples\n","Epoch 1/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 0.0084 - acc: 1.1869e-04\n","Epoch 2/100\n","16850/16850 [==============================] - 1s 53us/sample - loss: 1.9178e-04 - acc: 1.1869e-04\n","Epoch 3/100\n","16850/16850 [==============================] - 1s 53us/sample - loss: 6.1888e-05 - acc: 1.1869e-04\n","Epoch 4/100\n","16850/16850 [==============================] - 1s 55us/sample - loss: 4.1466e-05 - acc: 1.1869e-04\n","Epoch 5/100\n","16850/16850 [==============================] - 1s 53us/sample - loss: 3.4552e-05 - acc: 1.1869e-04\n","Epoch 6/100\n","16850/16850 [==============================] - 1s 55us/sample - loss: 3.3252e-05 - acc: 1.1869e-04\n","Epoch 7/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 3.1043e-05 - acc: 1.1869e-04\n","Epoch 8/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.9923e-05 - acc: 1.1869e-04\n","Epoch 9/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.8095e-05 - acc: 1.1869e-04\n","Epoch 10/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.7948e-05 - acc: 1.1869e-04\n","Epoch 11/100\n","16850/16850 [==============================] - 1s 61us/sample - loss: 2.8780e-05 - acc: 1.1869e-04\n","Epoch 12/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 2.5684e-05 - acc: 1.1869e-04\n","Epoch 13/100\n","16850/16850 [==============================] - 1s 55us/sample - loss: 2.6008e-05 - acc: 1.1869e-04\n","Epoch 14/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 2.6501e-05 - acc: 1.1869e-04\n","Epoch 15/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.3936e-05 - acc: 1.1869e-04\n","Epoch 16/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.3790e-05 - acc: 1.1869e-04\n","Epoch 17/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.5651e-05 - acc: 1.1869e-04\n","Epoch 18/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.4219e-05 - acc: 1.1869e-04\n","Epoch 19/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 2.3788e-05 - acc: 1.1869e-04\n","Epoch 20/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 2.4418e-05 - acc: 1.1869e-04\n","Epoch 21/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 2.3068e-05 - acc: 1.1869e-04\n","Epoch 22/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 2.2661e-05 - acc: 1.1869e-04\n","Epoch 23/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 2.3137e-05 - acc: 1.1869e-04\n","Epoch 24/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 2.0910e-05 - acc: 1.1869e-04\n","Epoch 25/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 2.1891e-05 - acc: 1.1869e-04\n","Epoch 26/100\n","16850/16850 [==============================] - 1s 55us/sample - loss: 2.1981e-05 - acc: 1.1869e-04\n","Epoch 27/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 2.0884e-05 - acc: 1.1869e-04\n","Epoch 28/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.1927e-05 - acc: 1.1869e-04\n","Epoch 29/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.1281e-05 - acc: 1.1869e-04\n","Epoch 30/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.0930e-05 - acc: 1.1869e-04\n","Epoch 31/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 2.0345e-05 - acc: 1.1869e-04\n","Epoch 32/100\n","16850/16850 [==============================] - 1s 63us/sample - loss: 2.1138e-05 - acc: 1.1869e-04\n","Epoch 33/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.9968e-05 - acc: 1.1869e-04\n","Epoch 34/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 2.0720e-05 - acc: 1.1869e-04\n","Epoch 35/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 2.0571e-05 - acc: 1.1869e-04\n","Epoch 36/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.9960e-05 - acc: 1.1869e-04\n","Epoch 37/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.9770e-05 - acc: 1.1869e-04\n","Epoch 38/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.9501e-05 - acc: 1.1869e-04\n","Epoch 39/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.9610e-05 - acc: 1.1869e-04\n","Epoch 40/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.9866e-05 - acc: 1.1869e-04\n","Epoch 41/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.9284e-05 - acc: 1.1869e-04\n","Epoch 42/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.8850e-05 - acc: 1.1869e-04\n","Epoch 43/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.8434e-05 - acc: 1.1869e-04\n","Epoch 44/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.7651e-05 - acc: 1.1869e-04\n","Epoch 45/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.8137e-05 - acc: 1.1869e-04\n","Epoch 46/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 1.8015e-05 - acc: 1.1869e-04\n","Epoch 47/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.7672e-05 - acc: 1.1869e-04\n","Epoch 48/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.8540e-05 - acc: 1.1869e-04\n","Epoch 49/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 1.8887e-05 - acc: 1.1869e-04\n","Epoch 50/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.7537e-05 - acc: 1.1869e-04\n","Epoch 51/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 1.8058e-05 - acc: 1.1869e-04\n","Epoch 52/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.7581e-05 - acc: 1.1869e-04\n","Epoch 53/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.7780e-05 - acc: 1.1869e-04\n","Epoch 54/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 1.7305e-05 - acc: 1.1869e-04\n","Epoch 55/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.6619e-05 - acc: 1.1869e-04\n","Epoch 56/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 1.8252e-05 - acc: 1.1869e-04\n","Epoch 57/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.6434e-05 - acc: 1.1869e-04\n","Epoch 58/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.7518e-05 - acc: 1.1869e-04\n","Epoch 59/100\n","16850/16850 [==============================] - 1s 55us/sample - loss: 1.7238e-05 - acc: 1.1869e-04\n","Epoch 60/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.7574e-05 - acc: 1.1869e-04\n","Epoch 61/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.6453e-05 - acc: 1.1869e-04\n","Epoch 62/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.7707e-05 - acc: 1.1869e-04\n","Epoch 63/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.6250e-05 - acc: 1.1869e-04\n","Epoch 64/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6770e-05 - acc: 1.1869e-04\n","Epoch 65/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6686e-05 - acc: 1.1869e-04\n","Epoch 66/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6134e-05 - acc: 1.1869e-04\n","Epoch 67/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.8825e-05 - acc: 1.1869e-04\n","Epoch 68/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.5857e-05 - acc: 1.1869e-04\n","Epoch 69/100\n","16850/16850 [==============================] - 1s 55us/sample - loss: 1.6659e-05 - acc: 1.1869e-04\n","Epoch 70/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6449e-05 - acc: 1.1869e-04\n","Epoch 71/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.6512e-05 - acc: 1.1869e-04\n","Epoch 72/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6495e-05 - acc: 1.1869e-04\n","Epoch 73/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.5270e-05 - acc: 1.1869e-04\n","Epoch 74/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.5902e-05 - acc: 1.1869e-04\n","Epoch 75/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6427e-05 - acc: 1.1869e-04\n","Epoch 76/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.7124e-05 - acc: 1.1869e-04\n","Epoch 77/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.7024e-05 - acc: 1.1869e-04\n","Epoch 78/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6076e-05 - acc: 1.1869e-04\n","Epoch 79/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.5822e-05 - acc: 1.1869e-04\n","Epoch 80/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.5648e-05 - acc: 1.1869e-04\n","Epoch 81/100\n","16850/16850 [==============================] - 1s 64us/sample - loss: 1.6477e-05 - acc: 1.1869e-04\n","Epoch 82/100\n","16850/16850 [==============================] - 1s 60us/sample - loss: 1.6265e-05 - acc: 1.1869e-04\n","Epoch 83/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.5960e-05 - acc: 1.1869e-04\n","Epoch 84/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6061e-05 - acc: 1.1869e-04\n","Epoch 85/100\n","16850/16850 [==============================] - 1s 59us/sample - loss: 1.6989e-05 - acc: 1.1869e-04\n","Epoch 86/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.5852e-05 - acc: 1.1869e-04\n","Epoch 87/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.5593e-05 - acc: 1.1869e-04\n","Epoch 88/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6005e-05 - acc: 1.1869e-04\n","Epoch 89/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6066e-05 - acc: 1.1869e-04\n","Epoch 90/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6673e-05 - acc: 1.1869e-04\n","Epoch 91/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.6136e-05 - acc: 1.1869e-04\n","Epoch 92/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.5689e-05 - acc: 1.1869e-04\n","Epoch 93/100\n","16850/16850 [==============================] - 1s 56us/sample - loss: 1.5635e-05 - acc: 1.1869e-04\n","Epoch 94/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.6287e-05 - acc: 1.1869e-04\n","Epoch 95/100\n","16850/16850 [==============================] - 1s 58us/sample - loss: 1.6438e-05 - acc: 1.1869e-04\n","Epoch 96/100\n","16850/16850 [==============================] - 1s 57us/sample - loss: 1.5844e-05 - acc: 1.1869e-04\n","Epoch 97/100\n","16850/16850 [==============================] - 1s 61us/sample - loss: 1.5462e-05 - acc: 1.1869e-04\n","Epoch 98/100\n","16850/16850 [==============================] - 1s 60us/sample - loss: 1.5724e-05 - acc: 1.1869e-04\n","Epoch 99/100\n","16850/16850 [==============================] - 1s 61us/sample - loss: 1.5560e-05 - acc: 1.1869e-04\n","Epoch 100/100\n","16850/16850 [==============================] - 1s 61us/sample - loss: 1.5835e-05 - acc: 1.1869e-04\n","4213/4213 [==============================] - 0s 35us/sample - loss: 1.1086e-05 - acc: 4.7472e-04\n","[1.108584916938663e-05, 0.0004747211]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PIh9yLVx9KE8","colab_type":"text"},"source":["### Different libraries \n","\n","To extend our search for a good prediction model, we also went and took a look at a different library: Sklearn. In this case we used a standard SGDRegressor. Next, we train, test and score the model again. Here we can see that this model scores great! This might not be good news, however, because this will most likely be an 'overfit'. This means that the model is trained *too well* and when it's presented some new data it will fail to accurately predict the next price."]},{"cell_type":"code","metadata":{"id":"xlFbucez9KE-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"4bedac5d-cb02-4bda-ea85-1ab8f911636b","executionInfo":{"status":"ok","timestamp":1575155787127,"user_tz":-60,"elapsed":86896,"user":{"displayName":"Jitse Wierdsma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA8hIhGegjl_BTyv004_anbBlaWTl6Bd7oIoW3Xjw=s64","userId":"13573355581921025641"}}},"source":["from sklearn.linear_model import SGDRegressor\n","\n","sgd =  SGDRegressor(max_iter=100)\n","\n","sgd.fit(train_X,train_y.values.ravel())\n","print (sgd.score(test_X,test_y.values.ravel()))\n","\n","pred = sgd.predict([test_X.loc[5]])\n","\n","print (min_max_scaler.inverse_transform( [pred]))\n","print (min_max_scaler.inverse_transform( [test_y.loc[5]]))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["0.9990707200847666\n","[[0.27337165]]\n","[[0.26793955]]\n"],"name":"stdout"}]}]}